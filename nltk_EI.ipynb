{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1a0499c7a4a50afe9d0222578684e6b7d0a5b28e1d6168b6dad088fd14a794c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## In this file, I create holdback set with single posts.\n",
    "## Resources\n",
    "[NLTK][https://stackabuse.com/text-classification-with-python-and-scikit-learn/]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, plot_confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "vectorizer_max_features = 1500\n",
    "chosen_classifier = MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import load_data_set, sanitize_posts\n",
    "myers_briggs = load_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_df = pd.DataFrame(myers_briggs, columns=['type', 'posts'])\n",
    "types = sorted(mb_df['type'].unique())\n",
    "\n",
    "post_list = [re.split('\\|\\|\\|+', post) for post in mb_df['posts']]\n",
    "post_df = pd.DataFrame(post_list)\n",
    "post_df.insert(loc=0, column='type', value=mb_df['type'])\n",
    "\n",
    "posts_by_type = {typ: mb_df[mb_df['type'] == typ] for typ in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_post_df = pd.read_csv('vertical_posts.csv', index_col=0)"
   ]
  },
  {
   "source": [
    "## Split personalities into components."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_df['EI'] = mb_df['type'].apply(lambda x: x[0])\n",
    "\n",
    "EI_df = mb_df[['EI', 'posts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = EI_df['posts'], EI_df['EI']\n",
    "# X, y = vertical_post_df['posts'], vertical_post_df['type']"
   ]
  },
  {
   "source": [
    "## Might want to remove URLs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_holdback, y_train_val, y_holdback = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sanitize_posts(X_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=vectorizer_max_features, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(X_train_val).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train_val, train_size=train_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = chosen_classifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chosen_classifier, vectorizer_max_features, train_size)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred2, average='micro'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred2, average=None))\n",
    "cr = classification_report(y_test, y_pred2)\n",
    "cr.split('\\n')"
   ]
  },
  {
   "source": [
    "## ROC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1], pos_label='I')\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for E-I');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_test, classifier.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "source": [
    "## Run model on verticalized holdbacks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdback_df = pd.DataFrame(zip(y_holdback, X_holdback), columns=('type', 'posts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdback_post_list = [re.split('\\|\\|\\|+', post) for post in holdback_df['posts']]\n",
    "holdback_post_df = pd.DataFrame(holdback_post_list)\n",
    "holdback_post_df.insert(loc=0, column='type', value=holdback_df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits posts of holdback set into single posts.\n",
    "def compress_posts(df):\n",
    "    result = []\n",
    "    df_length = range(len(df))\n",
    "\n",
    "    for i in df_length:\n",
    "        for j in range(57):\n",
    "            if df.iloc[i][j] != None:\n",
    "                result.append([df['type'][i], df.iloc[i][j]])\n",
    "    \n",
    "    return pd.DataFrame(result, columns=('type', 'post'))\n",
    "\n",
    "vertical_holdback = compress_posts(holdback_post_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sanitize_posts(vertical_holdback['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_X_holdback = vectorizer.transform(documents).toarray()\n",
    "vertical_X_holdback = tfidfconverter.fit_transform(vertical_X_holdback).toarray()\n",
    "pred_holdback = classifier.predict(vertical_X_holdback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chosen_classifier, vectorizer_max_features, train_size)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(vertical_holdback['type'], pred_holdback))\n",
    "print(\"Precision:\", precision_score(vertical_holdback['type'], pred_holdback, average='micro'))\n",
    "print(\"Precision:\", precision_score(vertical_holdback['type'], pred_holdback, average=None))\n",
    "cr = classification_report(vertical_holdback['type'], pred_holdback)\n",
    "cr.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(classifier, vertical_X_holdback, vertical_holdback['type'])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict_proba(vertical_X_holdback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(vertical_holdback['type'], classifier.predict_proba(vertical_X_holdback)[:,1], pos_label='I')\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for E-I');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_test, classifier.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert = \"Hi, everyone!  Iâ€™m a San Francisco native who attended Caltech in Pasadena and has spent time all over the country.  My favorite cities are San Francisco, Boston, Raleigh, and Denver.  I am a bootcamp veteran, having acquired a skill set in web development, and where I, amazingly, met Josh Shaman who now works for Metis.  I bike, play piano, and dance in my spare time.\"\n",
    "\n",
    "trans_albert = vectorizer.transform([albert]).toarray()\n",
    "trans_albert = tfidfconverter.transform(trans_albert).toarray()\n",
    "classifier.predict(trans_albert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}