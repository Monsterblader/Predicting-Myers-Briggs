{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1a0499c7a4a50afe9d0222578684e6b7d0a5b28e1d6168b6dad088fd14a794c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Resources\n",
    "[NLTK][https://stackabuse.com/text-classification-with-python-and-scikit-learn/]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import load_data_set\n",
    "myers_briggs = load_data_set()\n",
    "mb_df = pd.DataFrame(myers_briggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mb_df[1], mb_df[0]"
   ]
  },
  {
   "source": [
    "## Might want to remove URLs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0   1   0   0   0   0   0   0   6  21   4   3   0   0   0   0]\n [  0  65   0   2   0   0   0   0  13  36  10   9   0   0   0   1]\n [  0   1   7   2   0   0   0   0   6  13   7   4   0   0   0   0]\n [  0  10   0  61   0   0   0   0  14  21   9  29   0   0   1   0]\n [  0   0   0   1   0   0   0   0   3   5   1   3   0   0   0   0]\n [  0   1   0   0   0   0   0   0   3   4   0   1   0   0   0   0]\n [  0   1   1   0   0   0   0   0   2   3   0   1   0   0   0   0]\n [  0   0   0   0   0   0   0   0   3   5   0   3   0   0   0   0]\n [  0   4   0   2   0   0   0   0 222  63   4  10   0   0   0   0]\n [  1   3   0   1   0   0   0   0  16 306   3  12   0   0   0   0]\n [  0   2   0   3   0   0   0   0  24  41 136  32   0   0   1   0]\n [  0   2   0   3   0   0   0   0  11  42   6 213   0   0   0   0]\n [  0   0   0   0   0   0   0   0   4  17   4   5   3   0   0   0]\n [  0   2   0   1   0   0   0   0   7  35   1   7   0   3   0   0]\n [  0   2   0   2   0   0   0   0   2   7   3   6   0   0   4   0]\n [  0   2   0   0   0   0   0   0   6  13   4   8   0   0   0  27]]\n              precision    recall  f1-score   support\n\n        ENFJ       0.00      0.00      0.00        35\n        ENFP       0.68      0.48      0.56       136\n        ENTJ       0.88      0.17      0.29        40\n        ENTP       0.78      0.42      0.55       145\n        ESFJ       0.00      0.00      0.00        13\n        ESFP       0.00      0.00      0.00         9\n        ESTJ       0.00      0.00      0.00         8\n        ESTP       0.00      0.00      0.00        11\n        INFJ       0.65      0.73      0.69       305\n        INFP       0.48      0.89      0.63       342\n        INTJ       0.71      0.57      0.63       239\n        INTP       0.62      0.77      0.68       277\n        ISFJ       1.00      0.09      0.17        33\n        ISFP       1.00      0.05      0.10        56\n        ISTJ       0.67      0.15      0.25        26\n        ISTP       0.96      0.45      0.61        60\n\n    accuracy                           0.60      1735\n   macro avg       0.53      0.30      0.32      1735\nweighted avg       0.64      0.60      0.57      1735\n\n0.6034582132564842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0   1   0   0   0   0   0   0   6  21   4   3   0   0   0   0]\n [  0  65   0   2   0   0   0   0  13  36  10   9   0   0   0   1]\n [  0   1   7   2   0   0   0   0   6  13   7   4   0   0   0   0]\n [  0  10   0  61   0   0   0   0  14  21   9  29   0   0   1   0]\n [  0   0   0   1   0   0   0   0   3   5   1   3   0   0   0   0]\n [  0   1   0   0   0   0   0   0   3   4   0   1   0   0   0   0]\n [  0   1   1   0   0   0   0   0   2   3   0   1   0   0   0   0]\n [  0   0   0   0   0   0   0   0   3   5   0   3   0   0   0   0]\n [  0   4   0   2   0   0   0   0 222  63   4  10   0   0   0   0]\n [  1   3   0   1   0   0   0   0  16 306   3  12   0   0   0   0]\n [  0   2   0   3   0   0   0   0  24  41 136  32   0   0   1   0]\n [  0   2   0   3   0   0   0   0  11  42   6 213   0   0   0   0]\n [  0   0   0   0   0   0   0   0   4  17   4   5   3   0   0   0]\n [  0   2   0   1   0   0   0   0   7  35   1   7   0   3   0   0]\n [  0   2   0   2   0   0   0   0   2   7   3   6   0   0   4   0]\n [  0   2   0   0   0   0   0   0   6  13   4   8   0   0   0  27]]\n              precision    recall  f1-score   support\n\n        ENFJ       0.00      0.00      0.00        35\n        ENFP       0.68      0.48      0.56       136\n        ENTJ       0.88      0.17      0.29        40\n        ENTP       0.78      0.42      0.55       145\n        ESFJ       0.00      0.00      0.00        13\n        ESFP       0.00      0.00      0.00         9\n        ESTJ       0.00      0.00      0.00         8\n        ESTP       0.00      0.00      0.00        11\n        INFJ       0.65      0.73      0.69       305\n        INFP       0.48      0.89      0.63       342\n        INTJ       0.71      0.57      0.63       239\n        INTP       0.62      0.77      0.68       277\n        ISFJ       1.00      0.09      0.17        33\n        ISFP       1.00      0.05      0.10        56\n        ISTJ       0.67      0.15      0.25        26\n        ISTP       0.96      0.45      0.61        60\n\n    accuracy                           0.60      1735\n   macro avg       0.53      0.30      0.32      1735\nweighted avg       0.64      0.60      0.57      1735\n\n0.6034582132564842\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Create model and measure accuracy\n",
    "pipe.fit([x[0] for x in train], [x[1] for x in train]) \n",
    "pred_data = pipe.predict([x[0] for x in test]) \n",
    "for (sample, pred) in zip(test, pred_data):\n",
    "    print(sample, pred)\n",
    "print(\"Accuracy:\", accuracy_score([x[1] for x in test], pred_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_score([x[1] for x in test], pred_data, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_score([x[1] for x in test], pred_data, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report([x[1] for x in test], pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}