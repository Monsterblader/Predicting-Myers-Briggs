{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1a0499c7a4a50afe9d0222578684e6b7d0a5b28e1d6168b6dad088fd14a794c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## In this file, I create holdback set with single posts.\n",
    "## Resources\n",
    "[NLTK][https://stackabuse.com/text-classification-with-python-and-scikit-learn/]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.01\n",
    "vectorizer_max_features = 1500\n",
    "chosen_classifier = RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import load_data_set\n",
    "myers_briggs = load_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_df = pd.DataFrame(myers_briggs, columns=['type', 'posts'])\n",
    "types = sorted(mb_df['type'].unique())\n",
    "\n",
    "post_list = [re.split('\\|\\|\\|+', post) for post in mb_df['posts']]\n",
    "post_df = pd.DataFrame(post_list)\n",
    "post_df.insert(loc=0, column='type', value=mb_df['type'])\n",
    "\n",
    "posts_by_type = {typ: mb_df[mb_df['type'] == typ] for typ in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_post_df = pd.read_csv('vertical_posts.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mb_df['posts'], mb_df['type']\n",
    "# X, y = vertical_post_df['posts'], vertical_post_df['type']"
   ]
  },
  {
   "source": [
    "## Might want to remove URLs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_holdback, y_train_val, y_holdback = train_test_split(documents, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=vectorizer_max_features, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(X_train_val).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train_val, train_size=train_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier = chosen_classifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0   4   0   0   0   0   0   0  48  64   0  23   0   0   0   0]\n [  0 127   0   0   0   0   0   0  99 240   0  42   0   0   0   0]\n [  0  11   0   0   0   0   0   0  51  88   0  26   0   0   0   0]\n [  0  43   0   0   0   0   0   0 138 261   0  71   0   0   1   0]\n [  0   4   0   0   0   0   0   0   8  12   0   9   0   0   0   0]\n [  0   4   0   0   0   0   0   0   3  19   0   9   0   0   0   0]\n [  0   2   0   0   0   0   0   0   4  21   0   6   0   0   0   0]\n [  0   3   0   0   0   0   0   0  16  36   0   9   0   0   0   0]\n [  0  27   0   0   0   0   0   0 531 411   0 123   0   0   0   0]\n [  0  44   0   0   0   0   0   0 154 981   0 142   0   0   1   0]\n [  0  44   0   0   0   0   0   0 229 374   0 151   0   0   2   0]\n [  0  26   0   0   0   0   0   0 203 496   0 267   0   0   1   0]\n [  0   7   0   0   0   0   0   0  26  64   0  25   0   0   2   0]\n [  0  12   0   0   0   0   0   0  34 117   0  41   0   0   0   0]\n [  0   7   0   0   0   0   0   0  30  79   0  29   0   0   3   0]\n [  0  12   0   0   0   0   0   0  49 159   0  36   0   0   0   0]]\n              precision    recall  f1-score   support\n\n        ENFJ       0.00      0.00      0.00       139\n        ENFP       0.34      0.25      0.29       508\n        ENTJ       0.00      0.00      0.00       176\n        ENTP       0.00      0.00      0.00       514\n        ESFJ       0.00      0.00      0.00        33\n        ESFP       0.00      0.00      0.00        35\n        ESTJ       0.00      0.00      0.00        33\n        ESTP       0.00      0.00      0.00        64\n        INFJ       0.33      0.49      0.39      1092\n        INFP       0.29      0.74      0.41      1322\n        INTJ       0.00      0.00      0.00       800\n        INTP       0.26      0.27      0.27       993\n        ISFJ       0.00      0.00      0.00       124\n        ISFP       0.00      0.00      0.00       204\n        ISTJ       0.30      0.02      0.04       148\n        ISTP       0.00      0.00      0.00       256\n\n    accuracy                           0.30      6441\n   macro avg       0.09      0.11      0.09      6441\nweighted avg       0.19      0.30      0.22      6441\n\n0.2963825492935879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0   4   0   0   0   0   0   0  48  64   0  23   0   0   0   0]\n [  0 127   0   0   0   0   0   0  99 240   0  42   0   0   0   0]\n [  0  11   0   0   0   0   0   0  51  88   0  26   0   0   0   0]\n [  0  43   0   0   0   0   0   0 138 261   0  71   0   0   1   0]\n [  0   4   0   0   0   0   0   0   8  12   0   9   0   0   0   0]\n [  0   4   0   0   0   0   0   0   3  19   0   9   0   0   0   0]\n [  0   2   0   0   0   0   0   0   4  21   0   6   0   0   0   0]\n [  0   3   0   0   0   0   0   0  16  36   0   9   0   0   0   0]\n [  0  27   0   0   0   0   0   0 531 411   0 123   0   0   0   0]\n [  0  44   0   0   0   0   0   0 154 981   0 142   0   0   1   0]\n [  0  44   0   0   0   0   0   0 229 374   0 151   0   0   2   0]\n [  0  26   0   0   0   0   0   0 203 496   0 267   0   0   1   0]\n [  0   7   0   0   0   0   0   0  26  64   0  25   0   0   2   0]\n [  0  12   0   0   0   0   0   0  34 117   0  41   0   0   0   0]\n [  0   7   0   0   0   0   0   0  30  79   0  29   0   0   3   0]\n [  0  12   0   0   0   0   0   0  49 159   0  36   0   0   0   0]]\n              precision    recall  f1-score   support\n\n        ENFJ       0.00      0.00      0.00       139\n        ENFP       0.34      0.25      0.29       508\n        ENTJ       0.00      0.00      0.00       176\n        ENTP       0.00      0.00      0.00       514\n        ESFJ       0.00      0.00      0.00        33\n        ESFP       0.00      0.00      0.00        35\n        ESTJ       0.00      0.00      0.00        33\n        ESTP       0.00      0.00      0.00        64\n        INFJ       0.33      0.49      0.39      1092\n        INFP       0.29      0.74      0.41      1322\n        INTJ       0.00      0.00      0.00       800\n        INTP       0.26      0.27      0.27       993\n        ISFJ       0.00      0.00      0.00       124\n        ISFP       0.00      0.00      0.00       204\n        ISTJ       0.30      0.02      0.04       148\n        ISTP       0.00      0.00      0.00       256\n\n    accuracy                           0.30      6441\n   macro avg       0.09      0.11      0.09      6441\nweighted avg       0.19      0.30      0.22      6441\n\n0.2963825492935879\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> 1500 0.01\n",
      "Accuracy: 0.2963825492935879\n",
      "Precision: 0.2963825492935879\n",
      "Precision: [0.         0.33687003 0.         0.         0.         0.\n",
      " 0.         0.         0.3271719  0.28667446 0.         0.26461843\n",
      " 0.         0.         0.3        0.        ]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '        ENFJ       0.00      0.00      0.00       139',\n",
       " '        ENFP       0.34      0.25      0.29       508',\n",
       " '        ENTJ       0.00      0.00      0.00       176',\n",
       " '        ENTP       0.00      0.00      0.00       514',\n",
       " '        ESFJ       0.00      0.00      0.00        33',\n",
       " '        ESFP       0.00      0.00      0.00        35',\n",
       " '        ESTJ       0.00      0.00      0.00        33',\n",
       " '        ESTP       0.00      0.00      0.00        64',\n",
       " '        INFJ       0.33      0.49      0.39      1092',\n",
       " '        INFP       0.29      0.74      0.41      1322',\n",
       " '        INTJ       0.00      0.00      0.00       800',\n",
       " '        INTP       0.26      0.27      0.27       993',\n",
       " '        ISFJ       0.00      0.00      0.00       124',\n",
       " '        ISFP       0.00      0.00      0.00       204',\n",
       " '        ISTJ       0.30      0.02      0.04       148',\n",
       " '        ISTP       0.00      0.00      0.00       256',\n",
       " '',\n",
       " '    accuracy                           0.30      6441',\n",
       " '   macro avg       0.09      0.11      0.09      6441',\n",
       " 'weighted avg       0.19      0.30      0.22      6441',\n",
       " '']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "print(chosen_classifier, vectorizer_max_features, train_size)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred2, average='micro'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred2, average=None))\n",
    "cr = classification_report(y_test, y_pred2)\n",
    "cr.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}