{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1a0499c7a4a50afe9d0222578684e6b7d0a5b28e1d6168b6dad088fd14a794c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## In this file, I create holdback set with single posts.\n",
    "## Resources\n",
    "[NLTK][https://stackabuse.com/text-classification-with-python-and-scikit-learn/]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, plot_confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "random_state = 56\n",
    "vectorizer_max_features = 1500\n",
    "chosen_classifier = MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import load_data_set, sanitize_posts\n",
    "myers_briggs = load_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_df = pd.DataFrame(myers_briggs, columns=['type', 'posts'])\n",
    "types = sorted(mb_df['type'].unique())\n",
    "\n",
    "post_list = [re.split('\\|\\|\\|+', post) for post in mb_df['posts']]\n",
    "post_df = pd.DataFrame(post_list)\n",
    "post_df.insert(loc=0, column='type', value=mb_df['type'])\n",
    "\n",
    "posts_by_type = {typ: mb_df[mb_df['type'] == typ] for typ in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_post_df = pd.read_csv('vertical_posts.csv', index_col=0)"
   ]
  },
  {
   "source": [
    "## Split personalities into components."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_df['JP'] = mb_df['type'].apply(lambda x: x[3])\n",
    "\n",
    "JP_df = mb_df[['JP', 'posts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = len(JP_df[JP_df['JP'] == 'J'])\n",
    "P = len(JP_df[JP_df['JP'] == 'P'])\n",
    "\n",
    "plt.bar(['J', 'P'], [J, P])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = JP_df['posts'], JP_df['JP']\n",
    "# X, y = vertical_post_df['posts'], vertical_post_df['type']"
   ]
  },
  {
   "source": [
    "## Might want to remove URLs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_holdback, y_train_val, y_holdback = train_test_split(X, y, train_size=train_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_train_test = sanitize_posts(X_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(sanitized_train_test, y_train_val, train_size=train_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=vectorizer_max_features, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X_tfidf = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = chosen_classifier()\n",
    "classifier.fit(X_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "X_val_tfidf = tfidfconverter.transform(X_val_vectorized)\n",
    "y_pred = classifier.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_holdback = sanitize_posts(X_holdback)\n",
    "X_holdback_vectorized = vectorizer.transform(sanitized_holdback)\n",
    "X_holdback_tfidf = tfidfconverter.transform(X_holdback_vectorized)\n",
    "y_pred2 = model.predict(X_holdback_tfidf)\n",
    "\n",
    "print(confusion_matrix(y_holdback, y_pred2))\n",
    "print(classification_report(y_holdback, y_pred2))\n",
    "print(accuracy_score(y_holdback, y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chosen_classifier, vectorizer_max_features, train_size)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_holdback, y_pred2))\n",
    "print(\"Precision:\", precision_score(y_holdback, y_pred2, average='micro'))\n",
    "print(\"Precision:\", precision_score(y_holdback, y_pred2, average=None))\n",
    "cr = classification_report(y_holdback, y_pred2)\n",
    "cr.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_holdback, classifier.predict_proba(X_holdback_tfidf)[:,1], pos_label='P')\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for J-P');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_holdback, classifier.predict_proba(X_holdback_tfidf)[:,1]))"
   ]
  },
  {
   "source": [
    "## Run model on verticalized holdbacks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdback_df = pd.DataFrame(zip(y_holdback, X_holdback), columns=('type', 'posts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdback_post_list = [re.split('\\|\\|\\|+', post) for post in holdback_df['posts']]\n",
    "holdback_post_df = pd.DataFrame(holdback_post_list)\n",
    "holdback_post_df.insert(loc=0, column='type', value=holdback_df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits posts of holdback set into single posts.\n",
    "def compress_posts(df):\n",
    "    result = []\n",
    "    df_rows = range(len(df))\n",
    "    df_cols = range(len(df.iloc[0]) - 1)\n",
    "\n",
    "    for i in df_rows:\n",
    "        for j in df_cols:\n",
    "            if df.iloc[i][j] != None:\n",
    "                result.append([df['type'][i], df.iloc[i][j]])\n",
    "    \n",
    "    return pd.DataFrame(result, columns=('type', 'post'))\n",
    "\n",
    "vertical_holdback = compress_posts(holdback_post_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_holdback = sanitize_posts(vertical_holdback['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_X_holdback = vectorizer.transform(sanitized_holdback).toarray()\n",
    "vertical_X_holdback = tfidfconverter.fit_transform(vertical_X_holdback).toarray()\n",
    "pred_holdback = classifier.predict(vertical_X_holdback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chosen_classifier, vectorizer_max_features, train_size)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(vertical_holdback['type'], pred_holdback))\n",
    "print(\"Precision:\", precision_score(vertical_holdback['type'], pred_holdback, average='micro'))\n",
    "print(\"Precision:\", precision_score(vertical_holdback['type'], pred_holdback, average=None))\n",
    "cr = classification_report(vertical_holdback['type'], pred_holdback)\n",
    "cr.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(classifier, vertical_X_holdback, vertical_holdback['type'])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(vertical_holdback['type'], classifier.predict_proba(vertical_X_holdback)[:,1], pos_label='P')\n",
    "\n",
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for J-P');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_holdback, classifier.predict_proba(X_holdback_tfidf)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert = \"Hi, everyone!  I’m a San Francisco native who attended Caltech in Pasadena and has spent time all over the country.  My favorite cities are San Francisco, Boston, Raleigh, and Denver.  I am a bootcamp veteran, having acquired a skill set in web development, and where I, amazingly, met Josh Shaman who now works for Metis.  I bike, play piano, and dance in my spare time.\"\n",
    "\n",
    "trans_albert = vectorizer.transform([albert]).toarray()\n",
    "trans_albert = tfidfconverter.transform(trans_albert).toarray()\n",
    "classifier.predict(trans_albert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}