{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1a0499c7a4a50afe9d0222578684e6b7d0a5b28e1d6168b6dad088fd14a794c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Imoprt modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "# Get pandas and postgres to work together\n",
    "import pandas as pd\n",
    "\n",
    "# We are also going to do some basic viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "source": [
    "## Initialize environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)"
   ]
  },
  {
   "source": [
    "## Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import load_data_set\n",
    "myers_briggs = load_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_df = pd.DataFrame(myers_briggs)\n",
    "\n",
    "post_list = [re.split('\\|\\|\\|+', post) for post in mb_df[1]]\n",
    "post_df = pd.DataFrame(post_list)\n",
    "post_df.insert(loc=0, column='type', value=mb_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_df = pd.DataFrame(myers_briggs, columns=['type', 'posts'])\n",
    "types = sorted(mb_df['type'].unique())\n",
    "\n",
    "posts_by_type = {typ: mb_df[mb_df['type'] == typ] for typ in types}"
   ]
  },
  {
   "source": [
    "### For a baseline - create initial word vector."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in posts_by_type:\n",
    "    posts_by_type[i] = ''.join(posts_by_type[i]['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_ENFJ = vectorizer.fit_transform([posts_by_type['ENFJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ENFP = vectorizer.fit_transform([posts_by_type['ENFP']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ENTJ = vectorizer.fit_transform([posts_by_type['ENTJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ENTP = vectorizer.fit_transform([posts_by_type['ENTP']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ESFJ = vectorizer.fit_transform([posts_by_type['ESFJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ESFP = vectorizer.fit_transform([posts_by_type['ESFP']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ESTJ = vectorizer.fit_transform([posts_by_type['ESTJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ISTP = vectorizer.fit_transform([posts_by_type['ISTP']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_INFJ = vectorizer.fit_transform([posts_by_type['INFJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_INFP = vectorizer.fit_transform([posts_by_type['INFP']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_INTJ = vectorizer.fit_transform([posts_by_type['INTJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_INTP = vectorizer.fit_transform([posts_by_type['INTP']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ISFJ = vectorizer.fit_transform([posts_by_type['ISFJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ISFP = vectorizer.fit_transform([posts_by_type['ISFP']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ISTJ = vectorizer.fit_transform([posts_by_type['ISTJ']])\n",
    "vectorizer = CountVectorizer()\n",
    "X_ISTP = vectorizer.fit_transform([posts_by_type['ISTP']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(X_ISTP.toarray(), columns=vectorizer.get_feature_names())\n",
    "counts.T.sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[['reddit', 'help']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}